<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Forecasting for Economics and Business</title>
    <meta charset="utf-8" />
    <meta name="author" content="David Ubilava" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Forecasting for Economics and Business
## Lecture 6: Forecast Comparison Tests
### David Ubilava
### September 2020

---









# The Need for the Forecast Evaluation

We typically have several methods at hand to forecast an economic variable of interest.

The usual challenge is to identify the best model to forecast from.

One way to select the most adequate model is using in-sample goodness of fit measures (e.g., AIC or SIC). 

A more sensible approach to evaluate forecasts, at least from the standpoint of a forecaster, is their assessment in an out-of-sample environment.

---


# The Need for the Forecast Evaluation

Recall that models with the best in-sample fit don't necessarily produce the best out-of-sample forecasts:

- Better in-sample fit can be obtained by incorporating additional parameters in the model.
- The more complex models, however, extrapolate the estimated parameter uncertainty into the forecasts.

---


# Comparing Forecasts

Thus far we have applied the following algorithm to identify 'the best' among the competing forecasts:

- Select a loss function (e.g., quadratic loss).
- Obtain forecasts, the forecast errors, and the corresponding sample expected loss (e.g., root mean squared forecast error) for each model in consideration.
- Rank the models according to their sample expected loss values.
- Select the model with the lowest sample expected loss.

---


# Comparing Forecasts

But the loss function is a function of a random variable, and in practice we deal with sample information, so sampling variation needs to be taken into the account.

Statistical methods of evaluation are, therefore, desirable.

Here we will cover two tests for the hypothesis that two forecasts are equivalent, in the sense that the associated loss difference is not statistically significantly different from zero.

---


# Comparing Forecasts

Consider forecasts from two competing models `\(i\)` and `\(j\)`: `\(y_{t+h|t}^{i}\)` and `\(y_{t+h|t}^{j}\)`, with corresponding forecast errors: `\(e_{t+h|t}^{i}\)` and `\(e_{t+h|t}^{j}\)`.

The null hypothesis of equal predictive ability can be given in terms of the unconditional expectation of the loss difference: `$$H_0: E\left[\Delta L(e_{t+h|t})\right] = 0,$$` where `\(\Delta L(e_{t+h|t}) = L(e_{t+h|t}^{i})-L(e_{t+h|t}^{j})\)`.
		
---


# Relative Forecast Accuracy Tests

## Morgan-Granger-Newbold Test

The test is based on auxiliary variables: `\(u_{1,t+h|t} = e_{t+h|t}^{i}-e_{t+h|t}^{j}\)` and `\(u_{2,t+h|t} = e_{t+h|t}^{i}+e_{t+h|t}^{j}\)`. It follows that: `$$E(u_1,u_2) = MSFE(i)-MSFE(j),$$` thus, the hypothesis of interest is equivalent to testing whether the two auxillary variables are correlated.
		
---


# Relative Forecast Accuracy Tests

## Morgan-Granger-Newbold Test

The test statistic is: `$$\frac{r}{\sqrt{(P-1)^{-1}(1-r^2)}}\sim t_{P-1},$$` where `\(t_{P-1}\)` is a Student t distribution with `\(P-1\)` degrees of freedom, `\(P\)` is the length of the out-of-sample series, and `$$r=\frac{\hat{\sigma}_{u_1 u_2}}{\hat{\sigma}_{u_1}\hat{\sigma}_{u_2}}$$`
		
---


# Relative Forecast Accuracy Tests

## Morgan-Granger-Newbold Test

The Morgan-Granger-Newbold test relies on the assumption that forecast errors of the forecasts to be compared, are unbiased, normally distributed, and uncorrelated (with each other). These are rather strict requirements that are, often, violated in empirical applications.
		
---


# Relative Forecast Accuracy Tests

## Diebold-Mariano Test

This test relaxes the requirements on the forecast errors. 

The test statistic is: `$$\frac{\bar{d}}{\sqrt{\sigma_d^2/P}} \sim N(0,1),$$` where `\(\bar{d}=P^{-1}\sum_{t=1}^{P} d_t\)` and where `\(d_t \equiv \Delta L(e_{t+h|t})\)`. 
		
---


# Relative Forecast Accuracy Tests

## Diebold-Mariano Test

A modified version of the DM statistic, due to Harvey, Leybourne, and Newbold (1998), addresses the finite sample properties of the test, so that: `$$\sqrt{\frac{P+1-2h+P^{-1}h(h-1)}{P}}DM\sim t_{P-1},$$` where `\(t_{P-1}\)` is a Student t distribution with `\(P-1\)` degrees of freedom.
		
---


# Relative Forecast Accuracy Tests

In practice, the test of equal predictive ability can be applied within the framework of a regression model as follows: `$$\Delta L(e_{t+h|t}) = \beta + \upsilon_{t+h} \hspace{.5in} t = R,\ldots,T-h.$$`

The null of equal predictive ability is equivalent of testing `\(H_0: \beta = 0\)` in the OLS setting.

Because `\(\Delta L(e_{t+h|t})\)` are likely to be serially correlated, an autocorrelation consistent standard errors should be used for inference.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
