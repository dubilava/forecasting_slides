---
title: "Forecasting for Economics and Business"
subtitle: "Lecture 7: Forecast Combination"
author: "David Ubilava"
date: "`r format(Sys.time(), '%B %Y')`"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts, style.css]
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 11, fig.height = 7)
```


```{r echo=FALSE, include=FALSE, message=FALSE}
library(ggplot2)
```

# Forecast Combination

Choosing the best (most adequate) model for forecasting also implies discarding all other considered methods.

Discarded forecasts, however, could possibly have some useful information, not available in the selected forecast.

Thus, merely choosing the best model may be a sub-optimal strategy.


An alternative strategy is to use some information from all forecasts, i.e., *forecast combination*.

---


# Forecast Combination
	
Several factors support the idea of forecast combination:

- The concept is intuitively appealing (more information is better).
- Many forecast combination techniques are computationally simple and easy to apply
- Empirical evidence strongly supports the idea of combining forecast to improve accuracy.
- The concept of forecast combination leads naturally to the concept of *forecast encompassing* - a valuable tool in forecast evaluation.

---


# Forecast Combination

Consider two different methods, $i$ and $j$, each respectively yielding forecasts $y_{i,t+1|t}$ and $y_{j,t+1|t}$, and the associated forecast errors $e_{i,t+1|t} = y_{t+1}-y_{i,t+1|t}$ and $e_{j,t+1} = y_{t+1}-y_{j,t+1|t}$.

A combined forecast, $y_{c,t+1|t}$, would be expressed as: $$y_{c,t+1|t} = (1-\lambda)y_{i,t+1|t} + \lambda y_{j,t+1|t},$$ where $0 \leq \lambda \leq 1$ is a weight, and, thus, the combined forecast is a weighted average of the two individual forecasts.

Note: more than two forecasts can also be combined, but to keep the illustration simple, we will work with two forecasts here.

---


# Forecast Combination

A combined forecast error is: $$e_{c,t+1|t} = (1-\lambda)e_{i,t+1|t} + \lambda e_{j,t+1|t}$$

The mean of the combined forecast error (under the assumption of forecast error unbiasedness) is zero: $$E\left(e_{c,t+1|t}\right) = E\left[(1-\lambda)e_{i,t+1|t} + \lambda e_{j,t+1|t}\right] = 0$$

The variance of the combined forecast error is given by: $$Var\left(e_{c,t+1|t}\right) = (1-\lambda)^2 \sigma_i^2 + \lambda^2  \sigma_j^2 + 2\lambda(1-\lambda)\rho\sigma_i\sigma_j,$$ where $\sigma_i$ and $\sigma_j$ are the standard deviations of the individual forecast errors, and $\rho$ is a correlation between the two.

---


# Optimal Weights for Combination

A simple optimization routine yields an optimal weight (which minimizes the combined forecast error variance): $$\lambda^* = \frac{\sigma_i^2-\rho\sigma_i\sigma_j}{\sigma_i^2+\sigma_j^2-2\rho\sigma_i\sigma_j}$$

Substitute $\lambda^*$ in place of $\lambda$ in the foregoing equation to obtain: $$Var\left[e_{c,t+1|t}(\lambda^*)\right] = \sigma_c^2(\lambda^*) = \frac{\sigma_i^2\sigma_j^2(1-\rho^2)}{\sigma_i^2+\sigma_j^2-2\rho\sigma_i\sigma_j}$$


It can be shown that $\sigma_c^2(\lambda^*) \leq \min\{\sigma_i^2,\sigma_j^2\}$; that is, by combining forecasts we are not making things worse (if we use optimal weights).

---


# Optimal Weights for Combination

## Case 1: $\sigma_i = \sigma_j = \sigma$.

Suppose the individual forecasts are equally accurate, then the combined forecast error variance reduces to: $$\sigma_c^2(\lambda^*) = \frac{\sigma^2(1+\rho)}{2} \leq \sigma^2$$

The equation shows there are diversification gains even when the forecasts are equally accurate (unless the forecasts are perfectly correlated, in which case there are no additional benefits from combination).

---


# Optimal Weights for Combination

## Case 2: $\rho=0$.

Suppose the forecast errors are uncorrelated, then the sample estimator of $\lambda^*$ is given by: $$\lambda^* = \frac{\sigma_i^2}{\sigma_i^2+\sigma_j^2} = \frac{\sigma_j^{-2}}{\sigma_i^{-2}+\sigma_j^{-2}}$$

Thus, weights attached to forecasts are inversely proportional to their variance.

---


# Optimal Weights for Combination

## Case 3: $\sigma_i = \sigma_j = \sigma$ and $\rho=0$.

Suppose the individual forecasts are equally accurate and the forecast errors are uncorrelated, then the sample estimator of $\lambda^*$ reduces to $0.5$, resulting in the equal-weighted forecast combination: $$y_{c,t+1|t} = 0.5y_{i,t+1|t} + 0.5y_{j,t+1|t}$$

---


# Optimal Weights for Combination

In practice $\sigma_i$, $\sigma_j$, and $\rho$ are unknown.

If we work with $P$ out-of-sample forecasts, the sample estimator of $\lambda^*$ is: $$\hat{\lambda}^* = \frac{\hat{\sigma}_i^2-\hat{\sigma}_{ij}}{\hat{\sigma}_i^2+\hat{\sigma}_j^2-2\hat{\sigma}_{ij}},$$ where $\hat{\sigma}_i^2 = P^{-1}\sum_{t=1}^{P}{\left(i,e_{t+1|t}\right)^2}$ and $\hat{\sigma}_j^2 = P^{-1}\sum_{t=1}^{P}{\left(j,e_{t+1|t}\right)^2}$ are sample forecast error variances, and $\hat{\sigma}_{ij}=P^{-1}\sum_{t=1}^{P}{i,e_{t+1|t}e_{j,t+1|t}}$ is a sample forecast error covariance.

---


# Optimal Weights for Combination

The optimal weight has a straightforward interpretation in a regression setting. Rewrite previous equations as: $$y_{t+1} = (1-\lambda)y_{i,t+1|t} + \lambda y_{j,t+1|t} + e_{c,t+1|t}$$

It turns out that the equation is simply the least squares estimator of $\lambda$.

In more general terms: $$y_{t+1} = \alpha + \beta_1 y_{i,t+1|t} + \beta_2 y_{j,t+1|t} + e_{c,t+1|t}$$


---


# Forecast Encompassing

A special case of forecast combination is when $\lambda=0$ (or when $\lambda=1$). Such an outcome (of the optimal weights) is known as forecast encompassing.

It is said that $y_{i,t+1|t}$ encompasses $y_{j,t+1|t}$, when given that the former is available, the latter provides no additional useful information.

This is equivalent of testing the null hypothesis of $\lambda=0$ in the previous equation, which, after rearranging terms, yields the following regression: $$e_{i,t+1|t} = \lambda\left(e_{j,t+1|t}-e_{i,t+1|t}\right)+\varepsilon_{t+1},$$ where $\varepsilon_{t+1}\equiv e_{c,t+1|t}$.

---


# Forecast Encompassing

Alternatively, the forecast encompassing hypothesis is equivalent of testing the null hypothesis of $\lambda=0$ in the following regression:  $$e_{i,t+1|t} = \lambda y_{j,t+1|t}+\varepsilon_{t+1}$$

That is, the information set from the second method should not be of any value to (i.e. should not be correlated with) the forecast error from the first method.

---


# Forecast Encompassing

Another option is to test the null hypothesis of $\beta_2=0$ in the following regression setting: $$y_{t+1} = \alpha + \beta_1 y_{i,t+1|t} + \beta_2 y_{j,t+1|t} + \varepsilon_{t+1}$$

In this regression setting, one can, in fact, test a joint hypothesis that $\{\alpha,\beta_1,\beta_2\} = \{0,1,0\}$.

---

# Readings

Gonzalez-Rivera, Chapter 9



